# config.yaml

Train:
  tuning: True #True for hyperparamter training, false for single run-through
  batch_size: 128
  learning_rate: 0.001
  reg: 0.0005
  epochs: 7
  steps: [5, 7]
  warmup: 1
  momentum: 0.9
  dropout_rate: 0.5
  optimizer: Adam #Adam, SGD

network:
  model: SimpleModel # DropoutAndBatchnormModel, DropoutModel, SimpleModel

data:
  save_best: True
  normalize: True

loss:
  loss_type: CE #CE

file_paths:
  train_file_path: train_cifar10.npz
  test_file_path: test_cifar10.npz

Anonymization:
  method: cluster #cluster, laplace, dp, pca, permutation, random, None
  eps: 1.2
  min_samples: 3
  noise_scale: 0.5

Anonymization_tuning:
  eps_tuning: [20] #Approx over 5 and under 40
  min_samples_tuning: [5] #Approx under 100 and over 5
  noise_scale_tuning: [0.00]